---
title: "Validation of quantifying infant all-day restrained experiences at home using inertial sensors"
blank-lines-above-title: 2
shorttitle: "Quantify infant restrained time with sensors"
fig-dpi: 300
execute: 
  echo: false
  warning: false
  error: false
  cache: false
author:
  - name: XX
    orcid: XX
    email: XX
    affiliations:
      - id: id1
        name: University of California, Riverside
        department: Department of Psychology
  - name: XX
    corresponding: true
    orcid: XX
    email: XX
    affiliations:
      - id: id1
        name: University of California, Riverside
        department: Department of Psychology
      
author-note:
  blank-lines-above-author-note: 1
  # Disclosures condensed to one paragraph, but you can start a field with two line breaks to break them up: \n\nNew Paragraph
  disclosures:
    # Example: This study was registered at ClinicalTrials.gov (Identifier NTC998877).
    study-registration: ~
    # Acknowledge and cite data/materials to be shared.
    data-sharing: ~
    # Example: This article is based on data published in Pulaski (2017).
    # Example: This article is based on the dissertation completed by Graham (2018).    
    # Example: Sally Jones earns royalties from the sale of Test X.
    conflict-of-interest: ~
    # Example: This study was supported by Grant A123 from the National Science Foundation.
    financial-support: ~
    # Example: The authors are grateful for the technical assistance of Dr. X during the initial design and setup of our lab equipment.
    gratitude: ~
    # Example. Because the authors are equal contributors, order of authorship was determined by a fair coin toss.
    authorship-agreements: ~
abstract: "XXX"
keywords: [infant, restraint, everyday experiences, inertial sensors, machine learning]
bibliography: [references.bib]
format:
  apaquarto-docx: 
    floatsintext: false
  apaquarto-html: default
  apaquarto-typst: default
  apaquarto-pdf: 
    # can be jou (journal), man (manuscript), stu (student), or doc (document)
    # for now, tables and figures do not render properly in jou mode. 
    documentmode: man
    # can be 10pt, 11pt, or 12pt
    fontsize: 12pt
    # Integrate tables and figures in text
    floatsintext: false
    # a4 paper if true, letter size if false
    a4paper: false
    # suppresses loading of the lmodern font package
    nolmodern: false
    # Suppresses loading of the fontenc package
    nofontenc: false
    # Suppress the title above the introduction
    donotrepeattitle: false
    # In jou mode, use times or pslatex instead of txfonts
    notxfonts: false
    # In jou mode, use Computer Modern font instead of times
    notimes: false
    # In jou mode, cancels automatic stretching of tables to column width 
    notab: false
    # Uses Helvetica font in stu and man mode
    helv: false
    # In man and stu mode, neutralizes the \helvetica command
    nosf: false
    # In man and stu mode, uses typewriter font
    tt: false
    # Puts draft watermark on first page
    draftfirst: false
    # Puts draft watermark on all pages
    draftall: false
    # Masks references that are marked as the author's own
    mask: false
    journal: ~
    volume: ~
    course: ~
    professor: ~
    duedate: ~
    # Hides correspondence text
    nocorrespondence: false
---

```{r}
#| include: false
library(papaja)
library(knitr)
library(patchwork)
library(scales)
library(ggforce)
library(hms)
library(tidyverse)
library(lubridate)
library(rstatix)
library(janitor)
library(flextable)
library(effectsize)
```

```{r}
#| include: false

set.seed(2025)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)

theme_update(text = element_text(size = 14),
             axis.text.x = element_text(size = 14, color = "black"),
             axis.title.x = element_text(size = 16),
             axis.text.y = element_text(size = 14,  color = "black"),
             axis.title.y = element_text(size = 16),
             panel.background = element_blank(),panel.border = element_blank(),
             panel.grid.major = element_blank(),
             panel.grid.minor = element_blank(), axis.line = element_blank(),
             legend.key = element_rect(fill = "white"))

model_labels <- c("4_no_pos", "16_no_pos", "30_no_pos")
model_shapes <- c(5,1,2) %>% set_names(model_labels)
class_labels <- c("r", "u")
class_shapes <- c(5,1) %>% set_names(class_labels)
class_colors <- c("#0072B2","#E69F00") %>% set_names(class_labels)

indx <- c("balanced_accuracy","sensitivity","pos_pred_value","f1","prevalence_df")
indices <- c("Sensitivity", "Positive Predictive Value", "F1", "Prevalence Difference")

```

# Results
We first compared the model’s performance to human annotation of the windowed data set of the first 1.5 hours across all 142 sessions. We then compared the model’s estimate to previous works regarding infants’ full day restrained time and developmental change.

## Model Performance Compared to Human Annotation
```{r}
load("matrices.RData")
matrix_comb <- rbind(matrix_30, matrix_16, matrix_4)
matrix_comb <- matrix_comb %>%  
  clean_names() %>% 
  mutate(model = factor(model, levels=c("4_no_pos","16_no_pos","30_no_pos")),
         positive_class = factor(positive_class, levels=c('r','u'))) %>% 
  mutate(prevalence_df = detection_prevalence - prevalence)

# Descriptives
stats <- matrix_comb %>% 
  group_by(model, positive_class) %>% 
  summarize (mean_acc = mean(balanced_accuracy, na.rm=T),
             sd_acc = sd(balanced_accuracy, na.rm=T),
             mean_sen = mean(sensitivity, na.rm=T),
             sd_sen = sd(sensitivity, na.rm=T),
             mean_ppv = mean(pos_pred_value, na.rm=T),
             sd_ppv = sd(pos_pred_value, na.rm=T),
             mean_f1 = mean(f1, na.rm=T),
             sd_f1 = sd(f1, na.rm=T),
             mean_code_prev = mean(prevalence, na.rm=T),
             mean_pred_prev = mean(detection_prevalence, na.rm=T),
             .groups="drop") 

```


```{r tbl-indexbetweenmodels}
# Compare between models

table_mean <- matrix_comb %>%
  group_by(positive_class, model) %>%
  summarise(
    mean_acc = mean(balanced_accuracy, na.rm = TRUE),
    mean_sen = mean(sensitivity, na.rm = TRUE),
    mean_ppv = mean(pos_pred_value, na.rm = TRUE),
    mean_f1 = mean(f1, na.rm = TRUE),
    mean_prev_df = mean(prevalence_df, na.rm = TRUE),
    .groups="drop"
  ) %>%
  pivot_longer(mean_acc:mean_prev_df, names_to = "Indices", values_to = "mean") %>%
  pivot_wider(names_from = model, values_from = mean) %>% 
  mutate(Indices = recode(Indices,
                        "mean_acc" = "Accuracy",
                        "mean_sen" = "Sensitivity",
                        "mean_ppv" = "Positive Predictive Value",
                        "mean_f1" = "F1",
                        "mean_prev_df" = "Prevalence Difference")) %>%
  relocate("Indices", .before = "positive_class") %>% 
  mutate(Indices = factor(Indices, levels=c("Accuracy", 
                              "Sensitivity", 
                              "Positive Predictive Value", 
                              "F1", 
                              "Prevalence Difference"))) %>% 
  arrange(Indices) %>% 
  rename("Category" = "positive_class",
         "4s model" = "4_no_pos",
         "16s model" = "16_no_pos",
         "30s model" = "30_no_pos")

aov_mdl <- function(index, ctgr){
  temp_ds <- matrix_comb %>% filter(positive_class==ctgr)
  fmla <- reformulate("model", response = index)  # response ~ model
  anova <- tidy(aov(fmla, data = temp_ds))
}
aov_r <- map(indx, ~aov_mdl(index=.x, ctgr="r")) %>% 
  map2_dfr(indx, ~mutate(as.data.frame(.x), Indices = .y)) %>% 
  mutate(Category = "r")
aov_u <- map(indx, ~aov_mdl(index=.x, ctgr="u")) %>% 
  map2_dfr(indx, ~mutate(as.data.frame(.x), Indices = .y)) %>% 
  mutate(Category = "u")
table_aov <- rbind(aov_r, aov_u) %>% 
  mutate(df_resi = lead(df, n = 1)) %>% 
  filter(term=="model") %>% 
  mutate(df = str_glue("({df}, {df_resi})")) %>% 
  select(-term, -df_resi) %>% 
  rename("SS" = "sumsq",
         "MS" = "meansq",
         "F" = "statistic",
         "p" = "p.value") %>% 
  relocate("Indices", .before = "df") %>% 
  relocate("Category", .before = "df") %>% 
  relocate("df", .before = "p") %>%
  mutate(Indices = recode(Indices,
                        "balanced_accuracy" = "Accuracy",
                        "sensitivity" = "Sensitivity",
                        "pos_pred_value" = "Positive Predictive Value",
                        "f1" = "F1",
                        "prevalence_df" = "Prevalence Difference")) %>%
  mutate(Indices = factor(Indices, levels=c("Accuracy", 
                              "Sensitivity", 
                              "Positive Predictive Value", 
                              "F1", 
                              "Prevalence Difference"))) %>% 
  arrange(Indices)

table_btw_mdl <- cbind(table_mean, table_aov %>% select(-Indices, -Category)) %>% 
  slice(-2) %>% 
  mutate(p = ifelse(p < .001,"<.001",round(p,3)),
         p = str_remove(p, "^0")) %>% 
  mutate(across(where(is.numeric), ~ round(.x, 3)))
  # Still need to combine some rows, and add a heading as "accuracy" for three models 
```

```{r tbl-indexbetweenctgr}
# Compare between categories while controlling for models
lm_ctgr <- function(model_select){
  temp_ds <- matrix_comb %>% filter(model==model_select)
  list(
    sen = summary(lm(sensitivity ~ positive_class, data=temp_ds))$coefficients,
    ppv = summary(lm(pos_pred_value ~ positive_class, data=temp_ds))$coefficients,
    f1  = summary(lm(f1 ~ positive_class, data=temp_ds))$coefficients,
    prev_df = summary(lm(prevalence_df ~ positive_class, data=temp_ds))$coefficients
  )
}

tbl_ctgr_30 <- lm_ctgr("30_no_pos")%>% 
  map2_dfr(indices, ~ mutate(as.data.frame(.x), Indices = .y)) %>% 
  relocate("Indices", .before = "Estimate")%>% 
  rename(p = `Pr(>|t|)`, SE = `Std. Error`, t = `t value`) %>% 
  mutate(p = ifelse(p < .001,"<.001",round(p,3)),
         p = str_remove(p, "^0")) %>% 
  mutate(across(where(is.numeric), ~ round(.x, 3))) %>% 
  add_column(Term = rep(c("Intercept","Prediction of Unrestrained"), 4), .before = "Estimate") %>% 
  select(-SE) 

tbl_ctgr_16 <- lm_ctgr("16_no_pos") %>% 
  map2_dfr(indices, ~ mutate(as.data.frame(.x), Indices = .y)) %>% 
  relocate("Indices", .before = "Estimate")%>% 
  rename(p = `Pr(>|t|)`, SE = `Std. Error`, t = `t value`) %>% 
  mutate(p = ifelse(p < .001,"<.001",round(p,3)),
         p = str_remove(p, "^0")) %>% 
  mutate(across(where(is.numeric), ~ round(.x, 3))) %>% 
  add_column(Term = rep(c("Intercept","Prediction of Unrestrained"), 4), .before = "Estimate") %>% 
  select(-SE)

tbl_ctgr_4 <- lm_ctgr("4_no_pos") %>% 
  map2_dfr(indices, ~ mutate(as.data.frame(.x), Indices = .y)) %>% 
  relocate("Indices", .before = "Estimate")%>% 
  rename(p = `Pr(>|t|)`, SE = `Std. Error`, t = `t value`) %>% 
  mutate(p = ifelse(p < .001,"<.001",round(p,3)),
         p = str_remove(p, "^0")) %>% 
  mutate(across(where(is.numeric), ~ round(.x, 3))) %>% 
  add_column(Term = rep(c("Intercept","Prediction of Unrestrained"), 4), .before = "Estimate") %>% 
  select(-SE) 

tbl_ctgr <- cbind(tbl_ctgr_4, tbl_ctgr_16 %>% select(-Indices,-Term)) %>% 
  cbind(tbl_ctgr_30 %>% select(-Indices, -Term))

# ctgr_4 <- ctgr_4 %>% 
#   flextable() %>% flextable::theme_apa() %>% line_spacing(part = "all") %>% 
#   merge_v(j = "Indices") %>% fix_border_issues() %>% 
#   hline(i = seq(2,8,2))%>% 
#   padding(padding.top = 2, padding.bottom = 2) %>% 
#   set_table_properties(layout = "autofit", width = .6) %>% 
#   align(align = "center", part = "all")

```

```{r fig-indexcomparison}
# Sensitivity
p_sen <- ggplot(data=matrix_comb, aes(x=model, y=sensitivity, color=positive_class, shape=model))+
  geom_point(position = position_jitterdodge(
              jitter.width = 0.4,
              jitter.height = 0,
              dodge.width = 0.6),
             size = 5)+
  scale_color_manual(values=class_colors,labels=c("restrained","unrestrained")) +
  scale_shape_manual(values=model_shapes) +
  stat_summary(fun = mean,
               geom = "crossbar",
               aes(group = positive_class),  
               position = position_dodge(width = 0.6), 
               width = 0.4,
               color = "black") +
  labs(x="",
       y="Sensitivity",
       color="Category")+
  scale_x_discrete(labels = c("4s","16s","30s"))+
  scale_y_continuous(
    limits = c(0, 1),  
    breaks = c(0, 0.25, 0.5, 0.75, 1) 
  ) +
  guides(color = "none",shape="none")+
  theme_update()
p_sen

# Positive Predictive Value
p_ppv <- ggplot(data=matrix_comb, aes(x=model, y=pos_pred_value, color=positive_class, shape=model))+
  geom_point(position = position_jitterdodge(
    jitter.width = 0.4,
    jitter.height = 0,
    dodge.width = 0.6),
    size = 5)+
  scale_color_manual(values=class_colors,labels=c("restrained","unrestrained")) +
  scale_shape_manual(values=model_shapes) +
  stat_summary(fun = mean,
               geom = "crossbar",
               aes(group = positive_class),  
               position = position_dodge(width = 0.6), 
               width = 0.4,
               color = "black") +
  labs(x="",
       y="Positive Predictive Value",
       color="Category")+
  scale_x_discrete(labels = c("4s","16s","30s"))+
  scale_y_continuous(
    limits = c(0, 1),  
    breaks = c(0, 0.25, 0.5, 0.75, 1) 
  ) +
  guides(shape="none")+
  theme_update()
p_ppv
# F1 score
p_f1 <- ggplot(data=matrix_comb, aes(x=model, y=f1, shape=model, color=positive_class))+
  geom_point(position = position_jitterdodge(
    jitter.width = 0.4,
    jitter.height = 0,
    dodge.width = 0.6),
    size = 5)+
  scale_color_manual(values=class_colors,labels=c("restrained","unrestrained")) +
  scale_shape_manual(values=model_shapes) +
  stat_summary(fun = mean,
               geom = "crossbar",
               aes(group = positive_class),  
               position = position_dodge(width = 0.6), 
               width = 0.4,
               color = "black") +
  labs(x="Models' Window Size",
       y="F1",
       color="Category")+
  scale_x_discrete(labels = c("4s","16s","30s"))+
  scale_y_continuous(
    limits = c(0, 1),  
    breaks = c(0, 0.25, 0.5, 0.75, 1) 
  ) +
  guides(color = "none",shape="none")+
  theme_update()
p_f1
# Prevalence Difference
p_prev_df <- ggplot(data=matrix_comb, aes(x=model, y=prevalence_df, shape=model, color=positive_class))+
  geom_point(position = position_jitterdodge(
    jitter.width = 0.4,
    jitter.height = 0,
    dodge.width = 0.6),
    size = 5)+
  geom_hline(yintercept = 0, linetype = 'dashed')+
  scale_color_manual(values=class_colors,labels=c("restrained","unrestrained")) +
  scale_shape_manual(values=model_shapes) +
  stat_summary(fun = mean,
               geom = "crossbar",
               aes(group = positive_class),  
               position = position_dodge(width = 0.6), 
               width = 0.4,
               color = "black") +
  labs(x="Models' Window Size",
       y="Prevalence Difference",
       color="Category")+
  scale_x_discrete(labels = c("4s","16s","30s"))+
  scale_y_continuous(
    limits = c(-.8, .8),
    breaks = c(-.8, -.4, 0, .4, .8)
  ) +
  guides(shape = "none")+
  theme_update()
p_prev_df

# figure arrangement
ggpubr::ggarrange(p_sen, p_ppv, p_f1, p_prev_df, ncol = 2, nrow = 2, 
                  labels = c("A", "B", "C", "D"), 
                  label.x = 0, 
                  label.y = 1,
                  font.label = list(size = 16, face = "bold"),
                  widths=c(6,7), heights=c(4,4))
ggsave("figure/indices.png", width=13, height=8)
ggsave("figure/indices.eps", width=13, height=8)
```

We evaluated the following indices: (1) accuracy, (2) sensitivity, (3) positive predictive value, (4) F1, and (5) prevalence difference for all three models. Prevalence difference is a subtraction of a model prediction’s prevalence of certain category from the human annotation’s prevalence, a positive value indicating the models’ overall tendency to overestimate a category.

Models performed equally well in all indices. (Table) Indices mean and ANOVA results. XXX

Despite the overall good performance, the models presented predicting bias towards unrestrained category. (Table + Figure). The sensitivity for predicting unrestrained periods was significantly higher for all models. The positive predictive value for predicting unrestrained periods was generally lower for all models, but 16s and 30s models did not significantly over-predict the unrestrained periods as 4s model did. The F1 value for both categories was comparable regardless of the models’ window size. The prevalence difference value for unrestrained category was significantly higher for all models, but 30s model did not significantly overestimate unrestrained periods or underestimate restrained periods.

An ideal model should present high accuracy, balanced performance across categories, and minimal offset in overall prevalence compared to ground truth. Based on these criteria, we selected the 30-s window model and applied it to process the full-day data.


## Model Estimate Compared to Previous Studies
```{r}
load("whole-model-prediction.RData")
rm(ds, ds_sum_excl, ds_sum_excl0, id_demo, id_info)
# exclude sessions where total recording time is <3 hours
ds_excl <- ds_sum %>% filter(total_time < 3) #11 sessions 
ds_sum_excl <- ds_sum %>% filter(total_time >=3) #132 sessions left
ds_sum_excl <- ds_sum_excl %>% 
  filter(unique_id != "148/1",
         unique_id != "178/3",
         unique_id != "185/3")
```

```{r}
ds_sum_excl %>% 
  group_by(age_mo) %>% 
  summarize(mean = mean(unrestrained_prop),
            sd = sd(unrestrained_prop),
            .groups="drop")
ds_sum_excl %>% 
  group_by(age_group) %>% 
  summarize(mean = mean(unrestrained_prop),
            sd = sd(unrestrained_prop),
            .groups="drop")

summary(lm(unrestrained_prop ~ age_group, data = ds_sum_excl)) # t test

ggplot(ds_sum_excl) +
  geom_point(aes(x = agemo, y = unrestrained_prop)) + 
  geom_smooth(aes(x = agemo, y = unrestrained_prop), method = "lm", se = T) + 
  scale_x_continuous(name = "Age (mo.)", breaks = c(4,7,11,14), limits = c(3,15)) +
  scale_y_continuous(name = "Unrestrained time (%)", breaks = seq(0, 1, .25), limits = c(0,1))
ggsave("figure/age_related_change.png",width=6, height=4)
ggsave("figure/age_related_change.eps",width=6, height=4)

```

Next, we compared the 30s model’s estimates of full day restrained time duration with previous studies (XX). We excluded eleven sessions where the total recording time was less than 3 hours. We excluded another two sessions where a big chunk of duration should have been excluded due to sensors removal, but we did not have reliable time stamp of when to start excluding. We also excluded another one session where the family put the leggings on a wrong infant later into the session.

Using the rest 129 sessions, the model reported an average of XX% of awake time (*SD* = XX) being restrained for younger infants (4-7 months) and XX% (*SD* = XX) for older infants (11-14 months). Figure XX shows a clear decrease in the percent of restrained time from younger infants to older infants. These results are consistent with previous findings where XXX.


```{r}
# ARCHIVE
### Prevalence correlation scatter plot
p_prev_scatter_r <- ggplot(data=matrix_comb %>% 
                             filter(positive_class=="r" & model=="30_no_pos"), 
                           aes(x = prevalence, y = detection_prevalence))+
  geom_point(size = 5, color = class_colors[1]) +
  geom_abline(intercept = 0, slope = 1, color = "black") +
  scale_x_continuous(limits = c(0, 1)) +
  scale_y_continuous(limits = c(0, 1)) +
  theme_update() +
  labs(x = "Ground Truth Prevalence", y = "Detection Prevalence",
       title = "Restrained Prediction by 30s Model")
p_prev_scatter_r

p_prev_scatter_u <- ggplot(data=matrix_comb %>% 
                             filter(positive_class=="u" & model=="30_no_pos"), 
                           aes(x = prevalence, y = detection_prevalence))+
  geom_point(size = 5, color = class_colors[2]) +
  geom_abline(intercept = 0, slope = 1, color = "black") +
  scale_x_continuous(limits = c(0, 1)) +
  scale_y_continuous(limits = c(0, 1)) +
  theme_update() +
  labs(x = "Ground Truth Prevalence", y = "Detection Prevalence",
       title = "Unrestrained Pred by 30s Model")
p_prev_scatter_u

ggpubr::ggarrange(p_prev_scatter_r,p_prev_scatter_u, ncol = 2, nrow = 1, 
                  labels = c("A", "B"), 
                  label.x = 0, 
                  label.y = 1,
                  font.label = list(size = 16, face = "bold"),
                  widths=c(5,5), heights=c(5))
ggsave("figure/prevalence_scatter.png", width=10, height=5)
ggsave("figure/prevalence_scatter.eps", width=10, height=5)
```
